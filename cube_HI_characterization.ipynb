{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The preceeding ipynb is semi more general in selecting it's blurring region.\n",
    "# It is capable of selecting cuboid, i.e. unequal sides\n",
    "# This ipynb restricts to only cubes, i.e. equal sides, as an attempt to be more computationally efficient\n",
    "# The reason for this restriction relies on the assumption that the blurring region are spheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:40:31.131377Z",
     "start_time": "2020-07-13T18:40:31.125544Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import py21cmfast as p21c\n",
    "# import caffeine\n",
    "from datetime import datetime\n",
    "import logging, os\n",
    "from numba import njit, jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Python Zen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set logger to log caching activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('21cmFAST')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version of 21cmFAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:40:31.679355Z",
     "start_time": "2020-07-13T18:40:31.675874Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 21cmFAST version 3.0.0.dev5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using 21cmFAST version {p21c.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of cores running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads running = 16\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of threads running = {os.cpu_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset cache location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p21c.config['direc'] = '/lustre/aoc/projects/hera/wchin/21cmFAST-cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.482570Z",
     "start_time": "2020-07-13T16:47:07.478593Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def Gaussian(x):  # μ=0, σ=1/sqrt(2), π=1\n",
    "    Gaussian = np.exp(-x**2)\n",
    "    return Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the distance of each voxel to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.490164Z",
     "start_time": "2020-07-13T16:47:07.485545Z"
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def distance_from_coordinate(box_length):\n",
    "        \n",
    "    index = np.arange(-0.5*(box_length-1), 0.5*(box_length+1))\n",
    "\n",
    "    x_mesh, y_mesh, z_mesh = np.meshgrid(index, index, index, indexing='ij')\n",
    "    \n",
    "    distance = np.sqrt((x_mesh)**2 + (y_mesh)**2 + (z_mesh)**2)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cube_regions(box_length, number_of_coordinates, radius):\n",
    "    \n",
    "    np.random.seed()  # no entry: set seed to a randome number\n",
    "#     np.random.seed(4)  # specifying seed for testing purposes\n",
    "\n",
    "    coordinates = np.random.randint(0, box_length, size=(number_of_coordinates, 3))\n",
    "    \n",
    "    # cube indices \n",
    "    inds1 = (coordinates-radius).astype(int)\n",
    "    inds2 = (coordinates+radius+1).astype(int)  # ending index is not inclusive\n",
    "    \n",
    "\n",
    "    return inds1, inds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T04:52:03.906927Z",
     "start_time": "2020-07-02T04:52:03.902405Z"
    }
   },
   "source": [
    "## Select a Smaller Cube with Sides 2R+1 Voxels, Centered about the Random Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicing_the_cube(ind1, ind2, radius, box):\n",
    "        \n",
    "    if ind1[0] < 0:  # periodic boundary conditions\n",
    "        x_inds = np.r_[(ind1[0]+len(box)):len(box), 0:ind2[0]]\n",
    "    elif ind2[0] > len(box):\n",
    "        x_inds = np.r_[ind1[0]:len(box), 0:(ind2[0]-len(box))]\n",
    "    else:\n",
    "        x_inds = np.r_[ind1[0]:ind2[0]]\n",
    "\n",
    "    if ind1[1] < 0:\n",
    "        y_inds = np.r_[(ind1[1]+len(box)):len(box), 0:ind2[1]]\n",
    "    elif ind2[1] > len(box):\n",
    "        y_inds = np.r_[ind1[1]:len(box), 0:(ind2[1]-len(box))]\n",
    "    else:\n",
    "        y_inds = np.r_[ind1[1]:ind2[1]]\n",
    "\n",
    "    if ind1[2] < 0:\n",
    "        z_inds = np.r_[(ind1[2]+len(box)):len(box), 0:ind2[2]]\n",
    "    elif ind2[2] > len(box):\n",
    "        z_inds = np.r_[ind1[2]:len(box), 0:(ind2[2]-len(box))]\n",
    "    else:\n",
    "        z_inds = np.r_[ind1[2]:ind2[2]]\n",
    "                    \n",
    "    try:\n",
    "        output_box = box[np.ix_(x_inds, y_inds, z_inds)]\n",
    "        # box[indices]\n",
    "        \n",
    "    except IndexError:  # sample region larger than box.\n",
    "        print(f'coordinate array = {ind1 + radius}')\n",
    "        print(f'radius = {radius}')\n",
    "        print(f'box length = {len(box)}')\n",
    "        print(f'x_ind1 = {ind1[0]}')\n",
    "        print(f'x_ind2 = {ind2[0]}')\n",
    "        print(f'x_inds = {x_inds}')\n",
    "        print(f'y_ind1 = {ind1[1]}')\n",
    "        print(f'y_ind2 = {ind2[1]}')\n",
    "        print(f'y_inds = {y_inds}')\n",
    "        print(f'z_ind1 = {ind1[2]}')\n",
    "        print(f'z_ind2 = {ind2[2]}')\n",
    "        print(f'z_inds = {z_inds}')\n",
    "        \n",
    "    return output_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausssian Sphere Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.516644Z",
     "start_time": "2020-07-13T16:47:07.510222Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_sphere_average(distance_box, radius, input_box, shell_num, sigma_factor):\n",
    "    \n",
    "    mean = np.zeros(shell_num)\n",
    "\n",
    "    shell_radius_edges = np.linspace(0,1,shell_num+1)\n",
    "    # sigma_factor number of sigmas the weighting goes out to, sigma = radius\n",
    "    shell_center = 0.5*(shell_radius_edges[1:] + shell_radius_edges[:-1])*sigma_factor \n",
    "    weight = Gaussian(x=shell_center)\n",
    "    \n",
    "    for ii in range(shell_num):\n",
    "        condition = np.logical_and(\n",
    "            distance_box <= shell_radius_edges[ii+1]*radius, \n",
    "            distance_box > shell_radius_edges[ii]*radius\n",
    "        )\n",
    "        mean[ii] = np.mean(input_box[condition])  # inside shell mean\n",
    "        \n",
    "    Gaussian_mean = np.average(mean, weights=weight)\n",
    "    \n",
    "    return Gaussian_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hat Sphere Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.522437Z",
     "start_time": "2020-07-13T16:47:07.519045Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_hat_sphere_average(distance_box, radius, input_box):\n",
    "    \n",
    "    condition = distance_box <= radius\n",
    "    mean = np.mean(input_box[condition])\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hat Cube Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.528583Z",
     "start_time": "2020-07-13T16:47:07.525886Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def top_hat_cube_average(input_box):\n",
    "    \n",
    "    mean = np.mean(input_box)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure averaging region size is not larger than the box itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_averaging_radius_limit(averaging_radius, box_length):\n",
    "    # check to see if averaging region is larger than the box itself\n",
    "    if averaging_radius > (box_length-1)/2:\n",
    "        raise ValueError(f'Averaging_radius = {averaging_radius} > {(box_length-1)/2} = (Box Length-1)/2, \\\n",
    "averaging region is larger than the box itself.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sphere Blurring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def average_neutral_fraction_distribution(\n",
    "    box, \n",
    "    radius, \n",
    "    iteration, \n",
    "    shell_num=6, \n",
    "    sigma_factor=1.4370397097748921*3, \n",
    "    blur_shape=None\n",
    "):\n",
    "    \n",
    "    box = box.copy()  # make copy of input box to have a separate box\n",
    "    \n",
    "    mean_data = np.zeros(iteration)  # empty list for data collection\n",
    "    \n",
    "    \n",
    "    if blur_shape == 'Gaussian_sphere':\n",
    "        \n",
    "        \n",
    "# ====================================================================================================================\n",
    "        # Radius Ratio 1\n",
    "        radius = int(round(radius*1.4370397097748921*3))\n",
    "        \n",
    "        # Radius Ratio 2\n",
    "#         radius = int(round(radius*((4/3/np.sqrt(np.pi))**(1/3))*13/4))  \n",
    "            # 13/4 --> speculated correction factor\n",
    "# ====================================================================================================================\n",
    "\n",
    "        \n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "            \n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "        \n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            # mean\n",
    "            mean_data[i] = gaussian_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box, \n",
    "                shell_num, \n",
    "                sigma_factor\n",
    "            )\n",
    "        \n",
    "    elif blur_shape == 'top_hat_sphere':\n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "            \n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "        \n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            # mean\n",
    "            mean_data[i] = top_hat_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box\n",
    "            )\n",
    "            \n",
    "    elif blur_shape == 'top_hat_cube':\n",
    "                \n",
    "        # ratio determiend by equating the volumes of cube & sphere\n",
    "        radius = int(round((radius*((4*np.pi/3)**(1/3))-1)/2))  \n",
    "\n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "\n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            # mean\n",
    "            mean_data[i] = top_hat_cube_average(cube_region_box)\n",
    "    else:\n",
    "        \n",
    "        print('Blurring shape assumed to be a Gaussian sphere with 4 shells \\\n",
    "              weighted by equally spaced values from 0 sigma to 4 sigma.')\n",
    "                \n",
    "        \n",
    "# ====================================================================================================================\n",
    "        # Radius Ratio 1\n",
    "        radius = int(round(radius*1.4370397097748921*3))\n",
    "        \n",
    "        # Radius Ratio 2\n",
    "#         radius = int(round(radius*((4/3/np.sqrt(np.pi))**(1/3))*13/4))  \n",
    "            # 13/4 --> speculated correction factor\n",
    "# ====================================================================================================================\n",
    "        \n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "\n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "\n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            mean_data[i] = gaussian_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box, \n",
    "                shell_num, \n",
    "                sigma_factor\n",
    "            )\n",
    "            # mean\n",
    "            \n",
    "    return mean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.578877Z",
     "start_time": "2020-07-13T16:47:07.546390Z"
    }
   },
   "outputs": [],
   "source": [
    "def histogram(\n",
    "    y1s, \n",
    "    figure_shape, \n",
    "    y2s=None,\n",
    "    y3s=None,\n",
    "    marker_lines=None,\n",
    "    y1s_labels=None,\n",
    "    y2s_label=None,\n",
    "    y3s_label=None,\n",
    "    title=None, \n",
    "    shared_title=None,\n",
    "    shared_title_x_position=0.5,   # figure coordinates, max=1 I think\n",
    "    shared_title_y_position=0.92,\n",
    "    shared_x_label=None, \n",
    "    shared_x_label_x_position=0.5,\n",
    "    shared_x_label_y_position=0.08,\n",
    "    shared_y_label=None, \n",
    "    shared_y_label_x_position=0.07,\n",
    "    shared_y_label_y_postion=0.5,\n",
    "    x_start=0, \n",
    "    x_stop=1, \n",
    "    bin_num=int(1e3), \n",
    "    color='white', \n",
    "    figure_size=(18,7), \n",
    "    font_size=15, \n",
    "    horizontal_gap=0.05, \n",
    "    vertical_gap=0.05, \n",
    "    y_scale='linear', \n",
    "    y_notation='plain', \n",
    "    share_x_axis=True, \n",
    "    share_y_axis=True,\n",
    "    dpi=100\n",
    "):  # a: x start, b: x stop\n",
    "    \n",
    "    bin_edges = np.linspace(x_start, x_stop, bin_num) # bin_num of bins from 0-1\n",
    "    \n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    \n",
    "    if np.array(y1s).ndim > 2:  # hopefully more robust condition.\n",
    "        \n",
    "        fig, axes = plt.subplots(\n",
    "            figure_shape[0], \n",
    "            figure_shape[1], \n",
    "            figsize=figure_size, \n",
    "            sharex=share_x_axis, \n",
    "            sharey=share_y_axis, \n",
    "            gridspec_kw={\"hspace\":vertical_gap, 'wspace':horizontal_gap},\n",
    "            dpi=dpi\n",
    "        )\n",
    "        \n",
    "        if shared_title != None:\n",
    "            \n",
    "            fig.suptitle(\n",
    "                x=shared_title_x_position, \n",
    "                y=shared_title_y_position, \n",
    "                t=shared_title, ha='center', \n",
    "                size=1.5*font_size, \n",
    "                color=color\n",
    "            )\n",
    "            \n",
    "        if shared_x_label != None:  # shared x label\n",
    "            fig.text(\n",
    "                x=shared_x_label_x_position, \n",
    "                y=shared_x_label_y_position, \n",
    "                s=shared_x_label, ha='center', \n",
    "                size=font_size, \n",
    "                color=color\n",
    "            )\n",
    "\n",
    "        if shared_y_label != None:  # shared y label\n",
    "            fig.text(\n",
    "                x=shared_y_label_x_position, \n",
    "                y=shared_y_label_y_postion, \n",
    "                s=shared_y_label, \n",
    "                va='center', \n",
    "                rotation='vertical', \n",
    "                size=font_size, \n",
    "                color=color\n",
    "            )\n",
    "        \n",
    "        for i, y1 in enumerate(y1s):\n",
    "            \n",
    "            for ii, marker_line in enumerate(marker_lines):\n",
    "                axes.flatten()[i].plot(\n",
    "                    bin_centers, \n",
    "                    np.histogram(y1s[i,ii,:], bins=bin_edges)[0], \n",
    "                    marker_line,\n",
    "                    label=y1s_labels[ii]\n",
    "                )\n",
    "            \n",
    "            if iterable(y2s):\n",
    "                axes.flatten()[i].plot(\n",
    "                    bin_centers, \n",
    "                    np.histogram(y2s[i], bins=bin_edges)[0], \n",
    "                    '--', \n",
    "                    label=y2s_label\n",
    "                )\n",
    "                \n",
    "                if iterable(y3s):\n",
    "                    axes.flatten()[i].plot(\n",
    "                        bin_centers, \n",
    "                        np.histogram(y3s[i], bins=bin_edges)[0], \n",
    "                        label=y3s_label\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "            if y1s_labels != None:\n",
    "                axes.flatten()[i].legend()\n",
    "                \n",
    "            if title != None:\n",
    "                axes.flatten()[i].set_title(title[i], color=color, fontsize=font_size)\n",
    "                \n",
    "            axes.flatten()[i].set_yscale(y_scale)\n",
    "            \n",
    "            if y_notation == 'sci':\n",
    "                axes.flatten()[i].ticklabel_format(\n",
    "                    axis='y', \n",
    "                    style=y_notation, \n",
    "                    scilimits=(0,0), \n",
    "                    useMathText=True\n",
    "                )\n",
    "                \n",
    "            axes.flatten()[i].tick_params(\n",
    "                color=color, \n",
    "                labelcolor=color, \n",
    "                labelsize=font_size, \n",
    "                size=font_size\n",
    "            )  # font style\n",
    "\n",
    "            for spine in axes.flatten()[i].spines.values():  # figure color\n",
    "                spine.set_edgecolor(color)\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=figure_size)\n",
    "        \n",
    "        ax.plot(bin_centers, np.histogram(y1s, bins=bin_edges)[0], label=y1s_labels)\n",
    "        \n",
    "        if y2s != None:\n",
    "            ax.plot(bin_centers, np.histogram(y2s, bins=bin_edges)[0], '--', label=y2s_label)\n",
    "            \n",
    "            if y3s == None:\n",
    "                ax.legend()\n",
    "                \n",
    "            else:\n",
    "                ax.plot(bin_centers, np.histogram(y3s, bins=bin_edges)[0], '-.', label=y3s_label)\n",
    "                ax.legend()\n",
    "                \n",
    "        if title != None:\n",
    "            ax.set_title(title, color=color, fontsize=font_size)\n",
    "            \n",
    "        ax.set_yscale(y_scale)\n",
    "        \n",
    "        if y_notation == 'sci':\n",
    "            ax.ticklabel_format(axis='y', style=y_notation, scilimits=(0,0), useMathText=True)\n",
    "            \n",
    "        ax.tick_params(color=color, labelcolor=color, labelsize=font_size)  # font style\n",
    "\n",
    "        for spine in ax.spines.values():  # figure color\n",
    "            spine.set_edgecolor(color)\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if object is iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable(obj):\n",
    "    \n",
    "    try:\n",
    "        iter(obj)\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFP alternate neutral region size measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "def mfp(data, xth=0.5, boxsize=None, iterations = 10000000, verbose=True, upper_lim=False, bins=None, r_min=None, r_max=None):\n",
    "    \"\"\"\n",
    "    Determines the sizes using the Mean-Free-Path (MFP) approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input     : ndarray\n",
    "        2D/3D array of ionization fraction/brightness temperature.\n",
    "    xth       : float\n",
    "        The threshold value (Default: 0.5).\n",
    "    boxsize   : float\n",
    "        The boxsize in cMpc can be given (Default: conv.LB).\n",
    "    iterations: float\n",
    "        Number of iterations (Default: 1e7).\n",
    "    verbose   : bool\n",
    "        It prints the progress of the program (Default: True).\n",
    "    upper_lim : bool\n",
    "        It decides if the threshold is the upper limit or the lower limit (Default: False).\n",
    "    bins      : int\n",
    "        Give number of bins or an array of sizes to re-bin into (Default: None).\n",
    "    r_min     : float\n",
    "        Minimum size after rebinning (Default: None).\n",
    "    r_max     : float\n",
    "        Maximum size after rebinning (Default: None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r  : ndarray\n",
    "        sizes of the regions\n",
    "    dn : ndarray\n",
    "        probability of finding the corresponding size \n",
    "    \"\"\"\n",
    "    if boxsize is None:\n",
    "        boxsize = conv.LB\n",
    "        print('Boxsize is set to %.2f Mpc.'%boxsize) \n",
    "    dim = len(data.shape)\n",
    "    t1 = datetime.now()\n",
    "    if (upper_lim): \n",
    "        data = -1.*data\n",
    "        xth  = -1.*xth\n",
    "    check_box = (data>=xth).sum()\n",
    "    if check_box==0:\n",
    "        data = np.ones(data.shape)\n",
    "        iterations = 3\n",
    "    if dim == 2:\n",
    "        print(\"MFP method applied on 2D data (ver 1.0)\")\n",
    "        #out = mfp2d(data, xth, iterations=iterations, verbose=verbose)\n",
    "        out = mfp2d(data, xth, iterations=iterations, verbose=verbose)\n",
    "    elif dim == 3:\n",
    "        print(\"MFP method applied on 3D data (ver 1.0)\")\n",
    "        #out = mfp3d(data, xth, iterations=iterations, verbose=verbose)\n",
    "        out = mfp3d(data, xth, iterations=iterations, verbose=verbose)\n",
    "    else:\n",
    "        print(\"The data doesn't have the correct dimension\")\n",
    "        return 0\n",
    "    nn = out[0]/iterations\n",
    "    rr = out[1]\n",
    "    t2 = datetime.now()\n",
    "    runtime = (t2-t1).total_seconds()/60\n",
    "\n",
    "    print(\"\\nProgram runtime: %f minutes.\" %runtime)\n",
    "    if check_box==0:\n",
    "        print(\"There is no ROI in the data. Therefore, the BSD is zero everywhere.\")\n",
    "        return rr*boxsize/data.shape[0], np.zeros(rr.shape)\n",
    "    print(\"The output contains a tuple with three values: r, rdP/dr\")\n",
    "    print(\"The curve has been normalized.\")\n",
    "  \n",
    "    r0,p0 = rr*boxsize/data.shape[0], rr*nn #rr[nn.argmax()]*boxsize/data.shape[0]\n",
    "    if bins is not None: r0,p0 = rebin_bsd(r0, p0, bins=bins, r_min=r_min, r_max=r_max)\n",
    "    return r0, p0\n",
    "\n",
    "def rebin_bsd(rr, pp, bins=10, r_min=None, r_max=None):\n",
    "    fp = interpolate.interp1d(rr, pp, kind='cubic')\n",
    "    if np.array(bins).size == 1:\n",
    "        if r_min is None: r_min = rr.min()+1\n",
    "        if r_max is None: r_max = rr.max()-10\n",
    "        rs = 10**np.linspace(np.log10(r_min), np.log10(r_max), bins)\n",
    "    else: rs = np.array(bins)\n",
    "    return rs, fp(rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFP3D & 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import sys\n",
    "\n",
    "def mfp3d(arr, xth=0.5, iterations=10000000, verbose=True):\n",
    "    #3D interpolation is required\n",
    "    #RegularGridInterpolator in scipy(>0.14) is used to do the interpolation\n",
    "\n",
    "    info = arr.shape  # dimentions of the data box\n",
    "\n",
    "#=========================================================================================================\n",
    "    longest = int(max(arr.shape)*np.sqrt(3))  # longest distance between 2 points in the box, i.e. diagonal corners\n",
    "    # EDIT: switch the definition of longest to sqrt(3)*longest\n",
    "#=========================================================================================================\n",
    "    \n",
    "    num_sz  = np.zeros(longest)  # place holder with length of the longest axis\n",
    "\n",
    "    ar  = np.zeros(arr.shape)  # place holder with data box shape\n",
    "    ar[arr >= xth] = 1  # generating a binary box, xth = threshold\n",
    "\n",
    "    loc = np.argwhere(ar == 1)  # locations of ionized cells\n",
    "    rand_loc = np.random.randint(0, high=loc.shape[0], size=iterations)  # iterations number of random ionized locations\n",
    " \n",
    "    #==================================================================================\n",
    "    thetas   = np.random.randint(0, 180, size=iterations)  # should it be 0 to 180 deg?\n",
    "    # EDIT: switched upper limit from 360 to 180.\n",
    "    #==================================================================================\n",
    "\n",
    "    phis     = np.random.randint(0, 360, size=iterations)\n",
    "    ls       = np.sin(thetas*np.pi/180)*np.cos(phis*np.pi/180)  # dx\n",
    "    ms       = np.sin(thetas*np.pi/180)*np.sin(phis*np.pi/180)  # dy\n",
    "    ns       = np.cos(thetas*np.pi/180)  # dz\n",
    "    xs,ys,zs = loc[rand_loc,0],loc[rand_loc,1],loc[rand_loc,2]  # slicing ionized locations with [randome coordinate, (x,y,z)]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((np.arange(info[0]), np.arange(info[1]), np.arange(info[2])), ar, bounds_error=False, fill_value=0)\n",
    "\n",
    "    #=========================================================================================================\n",
    "    for rr in range(longest):  # steping 1 step along the ray for all directions.\n",
    "    # should it be sqrt(longestX^2, longestY^2, longestZ^2)?\n",
    "    # motivation: no rays will be longer than the longest axis?\n",
    "    # EDIT: switch the definition of longest to sqrt(3)*longest\n",
    "    #=========================================================================================================\n",
    "\n",
    "        xs,ys,zs = xs+ls,ys+ms,zs+ns  # steping by dx, dy, dz\n",
    "        pts    = np.vstack((xs,ys,zs)).T\n",
    "        vals   = interp_func(pts)\n",
    "        check  = np.argwhere(vals<=0.5)  # coordinates that are outsise ionized regions.\n",
    "        num_sz[rr] = check.shape[0]  # record the number of new rays terminated in this loop\n",
    "        xs,ys,zs = np.delete(xs, check),np.delete(ys, check),np.delete(zs, check)  # for the terminated rays,\n",
    "        ls,ms,ns = np.delete(ls, check),np.delete(ms, check),np.delete(ns, check)  # delete the forward step \n",
    "        if verbose:\n",
    "            perc = (rr+1)*100/longest\n",
    "            msg  = '%.1f'%perc + '%'\n",
    "            loading_verbose(msg)\n",
    "        if not xs.size: break\n",
    "    msg  = '100.0' + '%'\n",
    "    loading_verbose(msg)\n",
    "    size_px = np.arange(longest)\n",
    "    return num_sz, size_px\n",
    "\n",
    "def mfp2d(arr, xth=0.5, iterations=1000000, verbose=True):\n",
    "    #2D interpolation is required\n",
    "    #RegularGridInterpolator in scipy(>0.14) is used to do the interpolation\n",
    "\n",
    "    info    = arr.shape\n",
    "    longy\t= max([info[0], info[1]])\n",
    "    longest = int(np.sqrt(2)*longy)\n",
    "    num_sz  = np.zeros(longest)\n",
    "\n",
    "    ar  = np.zeros(arr.shape)\n",
    "    ar[arr >= xth] = 1\n",
    "\n",
    "    loc = np.argwhere(ar == 1)\n",
    "    rand_loc = np.random.randint(0, high=loc.shape[0], size=iterations)\n",
    "    thetas   = np.random.randint(0, 360, size=iterations)\n",
    "    ls       = np.sin(thetas*np.pi/180)\n",
    "    ms       = np.cos(thetas*np.pi/180)\n",
    "\n",
    "    xs,ys    = loc[rand_loc,0],loc[rand_loc,1]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((np.arange(info[0]), np.arange(info[1])), ar, bounds_error=False, fill_value=0)\n",
    "\n",
    "    for rr in range(longest):\n",
    "        xs,ys  = xs+ls,ys+ms\n",
    "        pts    = np.vstack((xs,ys)).T\n",
    "        vals   = interp_func(pts)\n",
    "        check  = np.argwhere(vals<=0.5)\n",
    "        num_sz[rr] = check.shape[0]\n",
    "        xs,ys  = np.delete(xs, check),np.delete(ys, check)\n",
    "        ls,ms  = np.delete(ls, check),np.delete(ms, check)\n",
    "        if verbose:\n",
    "            perc = (rr+1)*100/longest\n",
    "            msg  = '%.1f'%perc + '%'\n",
    "            loading_verbose(msg)\n",
    "        if not xs.size: break\n",
    "    msg  = '100.0' + '%'\n",
    "    loading_verbose(msg)\n",
    "    size_px = np.arange(longest)\n",
    "    return num_sz, size_px\n",
    "\n",
    "\n",
    "def loading_verbose(string):\n",
    "    msg = (\"Completed: \" + string )\n",
    "    sys.stdout.write('\\r'+msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friends of friends method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tools21cm.readthedocs.io/examples/tutorials.html#Bubble-size-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fof(data, xth=0.5, connectivity=1):\n",
    "    \"\"\"\n",
    "    Determines the sizes using the friends-of-friends approach.\n",
    "    It assumes the length of the grid as the linking length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: ndarray \n",
    "        The array containing the input data\n",
    "    xth: float \n",
    "        The threshold value (Default: 0.5)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    map: ndarray\n",
    "        array with each regions of interest label\n",
    "    sizes: list\n",
    "        all the sizes\n",
    "    \"\"\"\n",
    "    use_skimage=True\n",
    "    t1 = datetime.datetime.now()\n",
    "    data = (data>=xth)\n",
    "    if 'skimage' in sys.modules and use_skimage:\n",
    "        from skimage import morphology\n",
    "        out_map = morphology.label(data, connectivity=connectivity)\n",
    "        elements, size_list = np.unique(out_map, return_counts=True)\n",
    "        size_list = size_list[1:]  # first entry corresponds to background\n",
    "    else: out_map, size_list = FoF_search(data, xth)\n",
    "    t2 = datetime.datetime.now()\n",
    "    runtime = (t2-t1).total_seconds()/60\n",
    "\n",
    "    print(\"Program runtime: %f minutes.\" %runtime)\n",
    "    print(\"The output is a tuple containing output-map and volume-list array respectively.\")\n",
    "\n",
    "    return out_map, size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fof_sizes(sizes, bins=100, boxsize=None, normalize='box'):\n",
    "    lg = np.log10(np.array(sizes))\n",
    "    ht = np.histogram(lg, bins=bins)\n",
    "    xx = 10**ht[1]\n",
    "    yy = ht[0]*xx[:-1]\n",
    "    if boxsize is None: boxsize = conv.LB\n",
    "    if normalize=='ionized': zz = yy/np.sum(yy)\n",
    "    else: zz = yy/boxsize**3\n",
    "    dummy = zz[zz!=0].min()/10.\n",
    "    zz[zz==0] = dummy\n",
    "    zz = np.hstack((zz,dummy))\n",
    "    print(\"The output is Size, Size**2 dP/d(Size), lowest value\")\n",
    "    return xx, zz, dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementing a basic searching algorithm to identify grouped areas of high\n",
    "values in an array\n",
    "Can either be imported and used in a seperate script, or run via command line with an input file and an\n",
    "output file as arguments. Output file will be a string representation of a list, with no modifications, this can be read\n",
    "in python using the 'ast' module, with:\n",
    "sizes_list = ast.literal_eval(sizes_string)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "#from Queue import Queue\n",
    "from multiprocessing import Queue\n",
    "\n",
    "\n",
    "def FoF_search(array, threshold):\n",
    "    \"\"\"\n",
    "    :param array: n-dimensional scalar array to search\n",
    "    :param threshold: float\n",
    "    :return: (out_map, size_list) n-dimensional array with points filled with corresponding group number\n",
    "        (0 if not above threshold), and a 1D list containing group sizes\n",
    "    \"\"\"\n",
    "    def cycle_through_options(coord):    # generator which returns indices next to a given index\n",
    "        for i in range(len(coord)):\n",
    "            for j in [-1, 1]:\n",
    "                new_coordinate = [k for k in coord]\n",
    "                new_coordinate[i] += j\n",
    "                yield tuple(new_coordinate)\n",
    "\n",
    "    out_map = np.zeros(array.shape, dtype=int)   # creates an array with the same shape as the input search array\n",
    "    possibilities = zip(*np.where(array > threshold))  # creates a list of indices of points above the threshold\n",
    "    poss_set = set(possibilities)\n",
    "    \n",
    "    def recursive_search(point, current_group, currentsize):     # function to calculate group membership of a point\n",
    "        for testPoint in cycle_through_options(point):\n",
    "            if testPoint in poss_set and not out_map[testPoint]:\n",
    "                out_map[testPoint] = current_group\n",
    "                q.put(testPoint)\n",
    "                currentsize += 1\n",
    "        return currentsize\n",
    "    c = count()\n",
    "    #c.next()\n",
    "    next(c)\n",
    "    size_list = []\n",
    "    q = Queue()             # initialise a queue\n",
    "    for p in possibilities:     # start cycling through possible points\n",
    "        if not out_map[p]:           # if the point has not already been searched,\n",
    "            group = next(c)        # start a new group number\n",
    "            out_map[p] = group       # assign the corresponding point in the group map to this group\n",
    "            q.put(p)                # put the point in the queue\n",
    "            s = 1                   # s contains the new group size\n",
    "            while not q.empty():    # cycle till queue is empty\n",
    "                s = recursive_search(q.get(), group, s)  # search each neighbour recursively\n",
    "            size_list.append(s)     # add size of group to a list\n",
    "    return out_map, np.array(size_list)\n",
    "\n",
    "\n",
    "# Probably old outdated code that authors left around\n",
    "\n",
    "# def gaussian(dx, sig):\n",
    "#     \"\"\"returns a one dimensional gaussian\"\"\"\n",
    "#     return np.exp(-dx**2.0/(2.0*sig**2.0))\n",
    "\n",
    "\n",
    "# def halo3d(x, a, sigma, array_size):\n",
    "#     \"\"\"\n",
    "#     Returns an array with size arSize^3 and one gaussian distribution with amplitude a and s.d. sigma\n",
    "#     somewhere within that array\n",
    "#     :param x: 3d vector to be the mean of gaussian\n",
    "#     :param a: float amplitude\n",
    "#     :param sigma: float s.d.\n",
    "#     :param array_size: size of array to output\n",
    "#     :return: 3d array as detailed above\n",
    "#     \"\"\"\n",
    "#     ar = np.zeros(array_size, dtype=float)\n",
    "#     for i in range(array_size[0]):\n",
    "#         for j in range(array_size[1]):\n",
    "#             for k in range(array_size[2]):\n",
    "#                 dx = float(reduce(lambda foo, y: foo+y**2, [0, i-x[0], j-x[1], k-x[2]]))\n",
    "#                 ar[i, j, k] = a*gaussian(dx, sigma)\n",
    "#     return ar\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "#     import c2raytools as c2t\n",
    "#     try:\n",
    "#         infile = sys.arg[1]\n",
    "#         outfile = sys.argv[2]\n",
    "#         x_file = c2t.XfracFile(infile)\n",
    "#         ret, sizes = friend_of_friend_search(x_file.xi, 0.5)\n",
    "#         with open(outfile, 'w') as out_file:\n",
    "#             out_file.write(str(sizes))\n",
    "#     except IndexError as e:\n",
    "#         print(\"Error: expected an input ionised fraction file and an output file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosmological Parameters (Default is used when no input is specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.620136Z",
     "start_time": "2020-07-13T16:47:07.617575Z"
    }
   },
   "outputs": [],
   "source": [
    "cosmo_params = p21c.CosmoParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters, like box length, number of voxels (i.e. resolution) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.625008Z",
     "start_time": "2020-07-13T16:47:07.622093Z"
    }
   },
   "outputs": [],
   "source": [
    "BOX_LEN=301  # 300, 301\n",
    "HII_DIM=301  # 450, 301\n",
    "\n",
    "user_params = p21c.UserParams(\n",
    "    BOX_LEN=BOX_LEN,  # Box length in Mpc\n",
    "    DIM=4*HII_DIM,      # Number of Voxels for hight resolution \n",
    "    HII_DIM=HII_DIM,  # Number of Voxels for low resolution \n",
    "    N_THREADS=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating initial conditions box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:49:19.338938Z",
     "start_time": "2020-07-13T16:47:07.627140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution qued at 2020-07-31 22:52:41.978871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 23:04:37,751 | INFO | Existing init_boxes found and read in (seed=230806296593).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed at 2020-07-31 23:04:38.564842\n",
      "Execution time = 0:11:56.585971\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f'Excution qued at {start_time}')\n",
    "\n",
    "init_cond = p21c.initial_conditions(\n",
    "    cosmo_params=cosmo_params,\n",
    "    user_params=user_params,\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Execution completed at {end_time}')\n",
    "print(f'Execution time = {execution_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ionized boxes and total neutral fractions as a function of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 23:04:41,656 | INFO | Existing z=8.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:43,647 | INFO | Existing z=8.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:45,845 | INFO | Existing z=7.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:47,477 | INFO | Existing z=7.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:49,147 | INFO | Existing z=6.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:50,724 | INFO | Existing z=6.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:52,553 | INFO | Existing z=5.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:54,645 | INFO | Existing z=5.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-31 23:04:56,965 | INFO | Existing z=4.5 ionized boxes found and read in (seed=230806296593).\n"
     ]
    }
   ],
   "source": [
    "redshifts = np.arange(8.5, 4, -0.5)\n",
    "\n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "# redshifts = np.array([6.5])\n",
    "# ====================================================================================================================\n",
    "\n",
    "ionized_boxes = np.zeros((len(redshifts), HII_DIM, HII_DIM, HII_DIM))\n",
    "total_neutral_fractions = np.zeros(len(redshifts))\n",
    "\n",
    "for i, z in enumerate(redshifts):\n",
    "    ionized_boxes[i] = p21c.ionize_box(redshift=z, init_boxes=init_cond).xH_box\n",
    "    total_neutral_fractions[i] = np.mean(ionized_boxes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Average Neutral Fraction Distributions as a function of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T17:38:36.997883Z",
     "start_time": "2020-07-13T17:38:36.987749Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_distributions(\n",
    "    boxes=ionized_boxes,\n",
    "    radii=np.arange(8, 17, 1),\n",
    "    iterations=10**2,\n",
    "    sigma_factor=1.4370397097748921*3,\n",
    "    shell_number=6,\n",
    "    progress_status=True\n",
    "):\n",
    "\n",
    "    gaussians = np.zeros((len(redshifts), len(radii), iterations))\n",
    "    \n",
    "    \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#     cubes = np.zeros((len(radii), iterations))\n",
    "# ====================================================================================================================\n",
    "\n",
    "    # print progress and local time\n",
    "    if progress_status:\n",
    "        start_time = datetime.now()\n",
    "        current_time = start_time\n",
    "        print(f'Progress = 0%, localtime = {start_time}')\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#         cube = average_neutral_fraction_distribution(\n",
    "#                 box=boxes[0],\n",
    "#                 radius=radius,\n",
    "#                 iteration=iterations,\n",
    "#                 blur_shape='top_hat_cube'\n",
    "#         )\n",
    "        \n",
    "#         cubes[i, :] = cube\n",
    "# ====================================================================================================================\n",
    "        \n",
    "        for ii, radius in enumerate(radii):\n",
    "                        \n",
    "            gaussians[i, ii, :] = average_neutral_fraction_distribution(\n",
    "                box=box,\n",
    "                radius=radius,\n",
    "                iteration=iterations,\n",
    "                sigma_factor=sigma_factor,\n",
    "                shell_num=shell_number,\n",
    "                blur_shape='Gaussian_sphere'\n",
    "            )\n",
    "\n",
    "        # print progress and local time\n",
    "        if progress_status:\n",
    "            previous_time = current_time\n",
    "            current_time = datetime.now()\n",
    "            loop_time = current_time - previous_time\n",
    "            elapsed_time = current_time - start_time\n",
    "            print(f'progress = {int(round((i+1)*100/len(boxes)))}%, \\\n",
    "localtime = {current_time}, loopexecuted in {loop_time}, elapsedtime = {elapsed_time}')\n",
    "        \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#     return gaussians, cubes\n",
    "# ====================================================================================================================\n",
    "    \n",
    "    return gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the distributions and storing the data in global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "radii = np.arange(9, 1, -1)  # array([34, 32, 30,... 6, 4]) units: voxels (51, 3, -3)\n",
    "iterations = int(3*7.5e4)\n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "# gaussians, cubes = generate_distributions(\n",
    "# =================================================================================================================== \n",
    "\n",
    "gaussians = generate_distributions(\n",
    "    boxes=ionized_boxes,\n",
    "    radii=radii,\n",
    "    iterations=iterations,\n",
    "    sigma_factor=1.4370397097748921*3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:44:11.263417Z",
     "start_time": "2020-07-13T18:44:04.542540Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = int(3e2)\n",
    "histogram(\n",
    "    y1s=gaussians, \n",
    "    \n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "#     y2s=cubes,\n",
    "# =================================================================================================================== \n",
    "    \n",
    "    marker_lines=['-']*len(radii),\n",
    "    y1s_labels=[f'Radius={r*BOX_LEN/HII_DIM:.0f}Mpc' for r in radii],\n",
    "    bin_num=bins,\n",
    "    \n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "#     y2s_label='Cube',\n",
    "# =================================================================================================================== \n",
    "    \n",
    "    title=[f'Redshift={z}' for z in redshifts],\n",
    "    shared_title=f'Distribution of Average Neutral Fraction \\\n",
    "(format switch r&z, {bins} bins, {iterations:.2e} iterations)',\n",
    "    shared_y_label='Counts',\n",
    "    shared_x_label='Neutral Fraction',\n",
    "    figure_shape=(3,3), \n",
    "    figure_size=(18,18),\n",
    "    vertical_gap=0.1,\n",
    "    horizontal_gap=0.2,\n",
    "    y_scale='log',\n",
    "#     y_notation='sci',\n",
    "    share_y_axis=False,\n",
    "    dpi=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Neutral Region Size Distributions with mfp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFP_distributions(\n",
    "    boxes=ionized_boxes, \n",
    "    bins = int(1e3),\n",
    "    iterations=int(1e3)\n",
    "):\n",
    "    mfp_radii = np.zeros(bins)\n",
    "    mpf_radii_probabilities = np.zeros((len(redshifts), bins))\n",
    "    for i, box in enumerate(boxes):\n",
    "        mfp_radii, mpf_radii_probabilities[i, :] = mfp(\n",
    "            data=box,\n",
    "            boxsize=BOX_LEN,\n",
    "            iterations=iterations,\n",
    "            verbose=True, \n",
    "            upper_lim=False, \n",
    "            bins=bins, \n",
    "            r_min=None, \n",
    "            r_max=None\n",
    "        )\n",
    "    return mfp_radii, mpf_radii_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling function to generate neutral region size distributions with mfp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin_num = int(1e3)\n",
    "interation = int(6e7)\n",
    "start_time = datetime.now()\n",
    "print(f'Run started at {start_time}')\n",
    "mfp_neutral_region_size, mfp_size_probabilities = MFP_distributions(\n",
    "    boxes=ionized_boxes,\n",
    "    bins=bin_num,\n",
    "    iterations=interation\n",
    ")\n",
    "end_time = datetime.now()\n",
    "print(f'Run completed at {end_time}')\n",
    "print(f'Total runtime: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interation = int(6e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color='white'\n",
    "percent=0.61\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, mfp_size_probability in enumerate(mfp_size_probabilities):\n",
    "    plt.plot(\n",
    "        mfp_neutral_region_size[:int(percent*bin_num)], \n",
    "        mfp_size_probability[:int(percent*bin_num)], \n",
    "        '-',\n",
    "        label=f'z={redshifts[i]}, x_HI={total_neutral_fractions[i]*100:.2f}%, \\\n",
    "maxR={mfp_neutral_region_size[np.argmax(mfp_size_probability)]:.1f}'\n",
    "    )\n",
    "plt.legend()\n",
    "plt.tick_params(color=color, labelcolor=color)\n",
    "plt.xlabel('$R$ (Mpc)', color=color)\n",
    "plt.ylabel('$R\\mathrm{d}P/\\mathrm{d}R$', color=color)\n",
    "plt.title(f'Region Size Distribution of Neutral Fraction Box ({interation:.0e} iterations)', color=color)\n",
    "plt.rcParams['font.size'] = 18\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
    "u, counts = np.unique(a, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "out_map = morphology.label(ionized_boxes[4], connectivity=1)\n",
    "elements, size_list = np.unique(out_map, return_counts=True)  # why does elements have 1 extra entry?\n",
    "size_list = size_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color='white'\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.semilogy(elements[:50], size_list[:50])\n",
    "plt.tick_params(color=color, labelcolor=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list[:500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "21cmfast",
   "language": "python",
   "name": "21cmfast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
