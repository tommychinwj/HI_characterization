{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The preceeding ipynb is semi more general in selecting it's blurring region.\n",
    "# It is capable of selecting cuboid, i.e. unequal sides\n",
    "# This ipynb restricts to only cubes, i.e. equal sides, as an attempt to be more computationally efficient\n",
    "# The reason for this restriction relies on the assumption that the blurring region are spheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:40:31.131377Z",
     "start_time": "2020-07-13T18:40:31.125544Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import py21cmfast as p21c\n",
    "# import caffeine\n",
    "from datetime import datetime\n",
    "import logging, os\n",
    "from numba import njit, jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Python Zen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set logger to log caching activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('21cmFAST')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version of 21cmFAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:40:31.679355Z",
     "start_time": "2020-07-13T18:40:31.675874Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 21cmFAST version 3.0.0.dev5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using 21cmFAST version {p21c.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of cores running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads running = 16\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of threads running = {os.cpu_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset cache location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p21c.config['direc'] = '/lustre/aoc/projects/hera/wchin/21cmFAST-cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.482570Z",
     "start_time": "2020-07-13T16:47:07.478593Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def Gaussian(x):  # μ=0, σ=1/sqrt(2), π=1\n",
    "    Gaussian = np.exp(-x**2)\n",
    "    return Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the distance of each voxel to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.490164Z",
     "start_time": "2020-07-13T16:47:07.485545Z"
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def distance_from_coordinate(box_length):\n",
    "        \n",
    "    index = np.arange(-0.5*(box_length-1), 0.5*(box_length+1))\n",
    "\n",
    "    x_mesh, y_mesh, z_mesh = np.meshgrid(index, index, index, indexing='ij')\n",
    "    \n",
    "    distance = np.sqrt((x_mesh)**2 + (y_mesh)**2 + (z_mesh)**2)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cube_regions(box_length, number_of_coordinates, radius):\n",
    "    \n",
    "    np.random.seed()  # no entry: set seed to a randome number\n",
    "#     np.random.seed(4)  # specifying seed for testing purposes\n",
    "\n",
    "    coordinates = np.random.randint(0, box_length, size=(number_of_coordinates, 3))\n",
    "    \n",
    "    # cube indices \n",
    "    inds1 = (coordinates-radius).astype(int)\n",
    "    inds2 = (coordinates+radius+1).astype(int)  # ending index is not inclusive\n",
    "    \n",
    "\n",
    "    return inds1, inds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T04:52:03.906927Z",
     "start_time": "2020-07-02T04:52:03.902405Z"
    }
   },
   "source": [
    "## Select a Smaller Cube with Sides 2R+1 Voxels, Centered about the Random Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicing_the_cube(ind1, ind2, radius, box):\n",
    "        \n",
    "    if ind1[0] < 0:  # periodic boundary conditions\n",
    "        x_inds = np.r_[(ind1[0]+len(box)):len(box), 0:ind2[0]]\n",
    "    elif ind2[0] > len(box):\n",
    "        x_inds = np.r_[ind1[0]:len(box), 0:(ind2[0]-len(box))]\n",
    "    else:\n",
    "        x_inds = np.r_[ind1[0]:ind2[0]]\n",
    "\n",
    "    if ind1[1] < 0:\n",
    "        y_inds = np.r_[(ind1[1]+len(box)):len(box), 0:ind2[1]]\n",
    "    elif ind2[1] > len(box):\n",
    "        y_inds = np.r_[ind1[1]:len(box), 0:(ind2[1]-len(box))]\n",
    "    else:\n",
    "        y_inds = np.r_[ind1[1]:ind2[1]]\n",
    "\n",
    "    if ind1[2] < 0:\n",
    "        z_inds = np.r_[(ind1[2]+len(box)):len(box), 0:ind2[2]]\n",
    "    elif ind2[2] > len(box):\n",
    "        z_inds = np.r_[ind1[2]:len(box), 0:(ind2[2]-len(box))]\n",
    "    else:\n",
    "        z_inds = np.r_[ind1[2]:ind2[2]]\n",
    "            \n",
    "    indices = np.ix_(x_inds, y_inds, z_inds)\n",
    "        \n",
    "    try:\n",
    "        output_box = box[indices]\n",
    "        \n",
    "    except IndexError:  # sample region larger than box.\n",
    "        print(f'coordinate array = {ind1 + radius}')\n",
    "        print(f'radius = {radius}')\n",
    "        print(f'box length = {len(box)}')\n",
    "        print(f'x_ind1 = {ind1[0]}')\n",
    "        print(f'x_ind2 = {ind2[0]}')\n",
    "        print(f'x_inds = {x_inds}')\n",
    "        print(f'y_ind1 = {ind1[1]}')\n",
    "        print(f'y_ind2 = {ind2[1]}')\n",
    "        print(f'y_inds = {y_inds}')\n",
    "        print(f'z_ind1 = {ind1[2]}')\n",
    "        print(f'z_ind2 = {ind2[2]}')\n",
    "        print(f'z_inds = {z_inds}')\n",
    "        \n",
    "    return output_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausssian Sphere Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.516644Z",
     "start_time": "2020-07-13T16:47:07.510222Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_sphere_average(distance_box, radius, input_box, shell_num, sigma_factor):\n",
    "    \n",
    "    mean = np.zeros(shell_num)\n",
    "\n",
    "    shell_radius_edges = np.linspace(0,1,shell_num+1)\n",
    "    # sigma_factor number of sigmas the weighting goes out to, sigma = radius\n",
    "    shell_center = 0.5*(shell_radius_edges[1:] + shell_radius_edges[:-1])*sigma_factor \n",
    "    weight = Gaussian(x=shell_center)\n",
    "    \n",
    "    for ii in range(shell_num):\n",
    "        condition = np.logical_and(\n",
    "            distance_box <= shell_radius_edges[ii+1]*radius, \n",
    "            distance_box > shell_radius_edges[ii]*radius\n",
    "        )\n",
    "        inside_shell_mean = np.mean(input_box[condition])\n",
    "        mean[ii] = inside_shell_mean\n",
    "        \n",
    "    Gaussian_mean = np.average(mean, weights=weight)\n",
    "    \n",
    "    return Gaussian_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hat Sphere Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.522437Z",
     "start_time": "2020-07-13T16:47:07.519045Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_hat_sphere_average(distance_box, radius, input_box):\n",
    "    \n",
    "    condition = distance_box <= radius\n",
    "    mean = np.mean(input_box[condition])\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hat Cube Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.528583Z",
     "start_time": "2020-07-13T16:47:07.525886Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def top_hat_cube_average(input_box):\n",
    "    \n",
    "    mean = np.mean(input_box)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure averaging region size is not larger than the box itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_averaging_radius_limit(averaging_radius, box_length):\n",
    "    # check to see if averaging region is larger than the box itself\n",
    "    if averaging_radius > (box_length-1)/2:\n",
    "        raise ValueError(f'Averaging_radius = {averaging_radius} > {(box_length-1)/2} = (Box Length-1)/2, \\\n",
    "averaging region is larger than the box itself.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sphere Blurring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Average_Neutral_Fraction_Distribution(\n",
    "    box, \n",
    "    radius, \n",
    "    iteration, \n",
    "    shell_num=6, \n",
    "    sigma_factor=1.4370397097748921*3, \n",
    "    blur_shape=None\n",
    "):\n",
    "    \n",
    "    box = box.copy()  # make copy of input box to have a separate box\n",
    "    \n",
    "    mean_data = np.zeros(iteration)  # empty list for data collection\n",
    "    \n",
    "    \n",
    "    if blur_shape == 'Gaussian_sphere':\n",
    "        \n",
    "        \n",
    "# ====================================================================================================================\n",
    "        # Radius Ratio 1\n",
    "        radius = int(round(radius*1.4370397097748921*3))\n",
    "        \n",
    "        # Radius Ratio 2\n",
    "#         radius = int(round(radius*((4/3/np.sqrt(np.pi))**(1/3))*13/4))  \n",
    "            # 13/4 --> speculated correction factor\n",
    "# ====================================================================================================================\n",
    "\n",
    "        \n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "            \n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "        \n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            mean = gaussian_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box, \n",
    "                shell_num, \n",
    "                sigma_factor\n",
    "            )\n",
    "            mean_data[i] = mean\n",
    "        \n",
    "    elif blur_shape == 'top_hat_sphere':\n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "            \n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "        \n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            mean = top_hat_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box\n",
    "            )\n",
    "            mean_data[i] = mean\n",
    "            \n",
    "    elif blur_shape == 'top_hat_cube':\n",
    "                \n",
    "        # ratio determiend by equating the volumes of cube & sphere\n",
    "        radius = int(round((radius*((4*np.pi/3)**(1/3))-1)/2))  \n",
    "\n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "\n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            mean = top_hat_cube_average(cube_region_box)\n",
    "            mean_data[i] = mean\n",
    "    else:\n",
    "        \n",
    "        print('Blurring shape assumed to be a Gaussian sphere with 4 shells \\\n",
    "              weighted by equally spaced values from 0 sigma to 4 sigma.')\n",
    "                \n",
    "        \n",
    "# ====================================================================================================================\n",
    "        # Radius Ratio 1\n",
    "        radius = int(round(radius*1.4370397097748921*3))\n",
    "        \n",
    "        # Radius Ratio 2\n",
    "#         radius = int(round(radius*((4/3/np.sqrt(np.pi))**(1/3))*13/4))  \n",
    "            # 13/4 --> speculated correction factor\n",
    "# ====================================================================================================================\n",
    "        \n",
    "        \n",
    "        # check to see if averaging region is largert than the box itself\n",
    "        check_averaging_radius_limit(radius, len(box))\n",
    "\n",
    "        # used as condition to define a sphere within a cube\n",
    "        dist_frm_coord_box = distance_from_coordinate(radius*2+1)\n",
    "\n",
    "        # iteration number of random cube region indices in the box\n",
    "        rand_coord_inds1, rand_coord_inds2 = random_cube_regions(len(box), iteration, radius)  \n",
    "        \n",
    "        for i in range(iteration):\n",
    "            cube_region_box = slicing_the_cube(\n",
    "                rand_coord_inds1[i, :], \n",
    "                rand_coord_inds2[i, :], \n",
    "                radius, \n",
    "                box\n",
    "            )\n",
    "            mean_data[i] = gaussian_sphere_average(\n",
    "                dist_frm_coord_box, \n",
    "                radius, \n",
    "                cube_region_box, \n",
    "                shell_num, \n",
    "                sigma_factor\n",
    "            )\n",
    "            mean_data[i] = mean\n",
    "            \n",
    "    return mean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.578877Z",
     "start_time": "2020-07-13T16:47:07.546390Z"
    }
   },
   "outputs": [],
   "source": [
    "def histogram(\n",
    "    y1s, \n",
    "    figure_shape, \n",
    "    y2s=None,\n",
    "    y3s=None,\n",
    "    marker_lines=None,\n",
    "    y1s_labels=None,\n",
    "    y2s_label=None,\n",
    "    y3s_label=None,\n",
    "    title=None, \n",
    "    shared_title=None,\n",
    "    shared_title_x_position=0.5,   # figure coordinates, max=1 I think\n",
    "    shared_title_y_position=0.92,\n",
    "    shared_x_label=None, \n",
    "    shared_x_label_x_position=0.5,\n",
    "    shared_x_label_y_position=0.08,\n",
    "    shared_y_label=None, \n",
    "    shared_y_label_x_position=0.07,\n",
    "    shared_y_label_y_postion=0.5,\n",
    "    x_start=0, \n",
    "    x_stop=1, \n",
    "    bin_num=int(1e3), \n",
    "    color='white', \n",
    "    figure_size=(18,7), \n",
    "    font_size=15, \n",
    "    horizontal_gap=0.05, \n",
    "    vertical_gap=0.05, \n",
    "    y_scale='linear', \n",
    "    y_notation='plain', \n",
    "    share_x_axis=True, \n",
    "    share_y_axis=True,\n",
    "    dpi=100\n",
    "):  # a: x start, b: x stop\n",
    "    \n",
    "    bin_edges = np.linspace(x_start, x_stop, bin_num) # bin_num of bins from 0-1\n",
    "    \n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    \n",
    "    if np.array(y1s).ndim > 2:  # hopefully more robust condition.\n",
    "        \n",
    "        fig, axes = plt.subplots(\n",
    "            figure_shape[0], \n",
    "            figure_shape[1], \n",
    "            figsize=figure_size, \n",
    "            sharex=share_x_axis, \n",
    "            sharey=share_y_axis, \n",
    "            gridspec_kw={\"hspace\":vertical_gap, 'wspace':horizontal_gap},\n",
    "            dpi=dpi\n",
    "        )\n",
    "        \n",
    "        if shared_title != None:\n",
    "            \n",
    "            fig.suptitle(\n",
    "                x=shared_title_x_position, \n",
    "                y=shared_title_y_position, \n",
    "                t=shared_title, ha='center', \n",
    "                size=1.5*font_size, \n",
    "                color=color\n",
    "            )\n",
    "            \n",
    "        if shared_x_label != None:  # shared x label\n",
    "            fig.text(\n",
    "                x=shared_x_label_x_position, \n",
    "                y=shared_x_label_y_position, \n",
    "                s=shared_x_label, ha='center', \n",
    "                size=font_size, \n",
    "                color=color\n",
    "            )\n",
    "\n",
    "        if shared_y_label != None:  # shared y label\n",
    "            fig.text(\n",
    "                x=shared_y_label_x_position, \n",
    "                y=shared_y_label_y_postion, \n",
    "                s=shared_y_label, \n",
    "                va='center', \n",
    "                rotation='vertical', \n",
    "                size=font_size, \n",
    "                color=color\n",
    "            )\n",
    "        \n",
    "        for i, y1 in enumerate(y1s):\n",
    "            \n",
    "            for ii, marker_line in enumerate(marker_lines):\n",
    "                axes.flatten()[i].plot(\n",
    "                    bin_centers, \n",
    "                    np.histogram(y1s[i,ii,:], bins=bin_edges)[0], \n",
    "                    marker_line,\n",
    "                    label=y1s_labels[ii]\n",
    "                )\n",
    "            \n",
    "            if iterable(y2s):\n",
    "                axes.flatten()[i].plot(\n",
    "                    bin_centers, \n",
    "                    np.histogram(y2s[i], bins=bin_edges)[0], \n",
    "                    '--', \n",
    "                    label=y2s_label\n",
    "                )\n",
    "                \n",
    "                if iterable(y3s):\n",
    "                    axes.flatten()[i].plot(\n",
    "                        bin_centers, \n",
    "                        np.histogram(y3s[i], bins=bin_edges)[0], \n",
    "                        label=y3s_label\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "            if y1s_labels != None:\n",
    "                axes.flatten()[i].legend()\n",
    "                \n",
    "            if title != None:\n",
    "                axes.flatten()[i].set_title(title[i], color=color, fontsize=font_size)\n",
    "                \n",
    "            axes.flatten()[i].set_yscale(y_scale)\n",
    "            \n",
    "            if y_notation == 'sci':\n",
    "                axes.flatten()[i].ticklabel_format(\n",
    "                    axis='y', \n",
    "                    style=y_notation, \n",
    "                    scilimits=(0,0), \n",
    "                    useMathText=True\n",
    "                )\n",
    "                \n",
    "            axes.flatten()[i].tick_params(\n",
    "                color=color, \n",
    "                labelcolor=color, \n",
    "                labelsize=font_size, \n",
    "                size=font_size\n",
    "            )  # font style\n",
    "\n",
    "            for spine in axes.flatten()[i].spines.values():  # figure color\n",
    "                spine.set_edgecolor(color)\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=figure_size)\n",
    "        \n",
    "        ax.plot(bin_centers, np.histogram(y1s, bins=bin_edges)[0], label=y1s_labels)\n",
    "        \n",
    "        if y2s != None:\n",
    "            ax.plot(bin_centers, np.histogram(y2s, bins=bin_edges)[0], '--', label=y2s_label)\n",
    "            \n",
    "            if y3s == None:\n",
    "                ax.legend()\n",
    "                \n",
    "            else:\n",
    "                ax.plot(bin_centers, np.histogram(y3s, bins=bin_edges)[0], '-.', label=y3s_label)\n",
    "                ax.legend()\n",
    "                \n",
    "        if title != None:\n",
    "            ax.set_title(title, color=color, fontsize=font_size)\n",
    "            \n",
    "        ax.set_yscale(y_scale)\n",
    "        \n",
    "        if y_notation == 'sci':\n",
    "            ax.ticklabel_format(axis='y', style=y_notation, scilimits=(0,0), useMathText=True)\n",
    "            \n",
    "        ax.tick_params(color=color, labelcolor=color, labelsize=font_size)  # font style\n",
    "\n",
    "        for spine in ax.spines.values():  # figure color\n",
    "            spine.set_edgecolor(color)\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if object is iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable(obj):\n",
    "    \n",
    "    try:\n",
    "        iter(obj)\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFP alternate neutral region size measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfp(data, xth=0.5, boxsize=None, iterations = 10000000, verbose=True, upper_lim=False, bins=None, r_min=None, r_max=None):\n",
    "    \"\"\"\n",
    "    Determines the sizes using the Mean-Free-Path (MFP) approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input     : ndarray\n",
    "        2D/3D array of ionization fraction/brightness temperature.\n",
    "    xth       : float\n",
    "        The threshold value (Default: 0.5).\n",
    "    boxsize   : float\n",
    "        The boxsize in cMpc can be given (Default: conv.LB).\n",
    "    iterations: float\n",
    "        Number of iterations (Default: 1e7).\n",
    "    verbose   : bool\n",
    "        It prints the progress of the program (Default: True).\n",
    "    upper_lim : bool\n",
    "        It decides if the threshold is the upper limit or the lower limit (Default: False).\n",
    "    bins      : int\n",
    "        Give number of bins or an array of sizes to re-bin into (Default: None).\n",
    "    r_min     : float\n",
    "        Minimum size after rebinning (Default: None).\n",
    "    r_max     : float\n",
    "        Maximum size after rebinning (Default: None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r  : ndarray\n",
    "        sizes of the regions\n",
    "    dn : ndarray\n",
    "        probability of finding the corresponding size \n",
    "    \"\"\"\n",
    "    if boxsize is None:\n",
    "        boxsize = conv.LB\n",
    "        print('Boxsize is set to %.2f Mpc.'%boxsize) \n",
    "    dim = len(data.shape)\n",
    "    t1 = datetime.datetime.now()\n",
    "    if (upper_lim): \n",
    "        data = -1.*data\n",
    "        xth  = -1.*xth\n",
    "    check_box = (data>=xth).sum()\n",
    "    if check_box==0:\n",
    "        data = np.ones(data.shape)\n",
    "        iterations = 3\n",
    "    if dim == 2:\n",
    "        print(\"MFP method applied on 2D data (ver 1.0)\")\n",
    "        #out = mfp2d(data, xth, iterations=iterations, verbose=verbose)\n",
    "        out = mfp_np.mfp2d(data, xth, iterations=iterations, verbose=verbose)\n",
    "    elif dim == 3:\n",
    "        print(\"MFP method applied on 3D data (ver 1.0)\")\n",
    "        #out = mfp3d(data, xth, iterations=iterations, verbose=verbose)\n",
    "        out = mfp_np.mfp3d(data, xth, iterations=iterations, verbose=verbose)\n",
    "    else:\n",
    "        print(\"The data doesn't have the correct dimension\")\n",
    "        return 0\n",
    "    nn = out[0]/iterations\n",
    "    rr = out[1]\n",
    "    t2 = datetime.datetime.now()\n",
    "    runtime = (t2-t1).total_seconds()/60\n",
    "\n",
    "    print(\"\\nProgram runtime: %f minutes.\" %runtime)\n",
    "    if check_box==0:\n",
    "        print(\"There is no ROI in the data. Therefore, the BSD is zero everywhere.\")\n",
    "        return rr*boxsize/data.shape[0], np.zeros(rr.shape)\n",
    "    print(\"The output contains a tuple with three values: r, rdP/dr\")\n",
    "    print(\"The curve has been normalized.\")\n",
    "\n",
    "    r0,p0 = rr*boxsize/data.shape[0], rr*nn #rr[nn.argmax()]*boxsize/data.shape[0]\n",
    "    if bins is not None: r0,p0 = rebin_bsd(r0, p0, bins=bins, r_min=r_min, r_max=r_max)\n",
    "    return r0, p0\n",
    "\n",
    "def rebin_bsd(rr, pp, bins=10, r_min=None, r_max=None):\n",
    "    fp = interp1d(rr, pp, kind='cubic')\n",
    "    if np.array(bins).size == 1:\n",
    "        if r_min is None: r_min = rr.min()+1\n",
    "        if r_max is None: r_max = rr.max()-10\n",
    "        rs = 10**np.linspace(np.log10(r_min), np.log10(r_max), bins)\n",
    "    else: rs = np.array(bins)\n",
    "    return rs, fp(rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFP3D & 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import sys\n",
    "\n",
    "def mfp3d(arr, xth=0.5, iterations=10000000, verbose=True):\n",
    "    #3D interpolation is required\n",
    "    #RegularGridInterpolator in scipy(>0.14) is used to do the interpolation\n",
    "\n",
    "    info = arr.shape  # dimentions of the data box\n",
    "    longest = max(arr.shape)  # longest axis\n",
    "    num_sz  = np.zeros(longest)  # place holder with length of the longest axis\n",
    "\n",
    "    ar  = np.zeros(arr.shape)  # place holder with data box shape\n",
    "    ar[arr >= xth] = 1  # generating a binary box, xth = threshold\n",
    "\n",
    "    loc = np.argwhere(ar == 1)  # locations of ionized cells\n",
    "    rand_loc = np.random.randint(0, high=loc.shape[0], size=iterations)  # iterations number of random ionized locations\n",
    "    #==================================================================================\n",
    "    thetas   = np.random.randint(0, 180, size=iterations)  # should it be 0 to 180 deg?\n",
    "    # EDIT: switched upper limit from 360 to 180.\n",
    "    #==================================================================================\n",
    "\n",
    "    phis     = np.random.randint(0, 360, size=iterations)\n",
    "    ls       = np.sin(thetas*np.pi/180)*np.cos(phis*np.pi/180)  # dx\n",
    "    ms       = np.sin(thetas*np.pi/180)*np.sin(phis*np.pi/180)  # dy\n",
    "    ns       = np.cos(thetas*np.pi/180)  # dz\n",
    "    xs,ys,zs = loc[rand_loc,0],loc[rand_loc,1],loc[rand_loc,2]  # slicing ionized locations with [randome coordinate, (x,y,z)]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((np.arange(info[0]), np.arange(info[1]), np.arange(info[2])), ar, bounds_error=False, fill_value=0)\n",
    "\n",
    "    #=========================================================================================================\n",
    "    for rr in range(int(longest*np.sqrt(3))):  # steping 1 step along the ray for all directions.\n",
    "    # should it be sqrt(longestX^2, longestY^2, longestZ^2)?\n",
    "    # motivation: no rays will be longer than the longest axis?\n",
    "    # EDIT switched range(longest) to range(int(longest*np.sqrt(3))) which reflects the diagonal of the cube\n",
    "    #=========================================================================================================\n",
    "\n",
    "        xs,ys,zs = xs+ls,ys+ms,zs+ns  # steping by dx, dy, dz\n",
    "        pts    = np.vstack((xs,ys,zs)).T\n",
    "        vals   = interp_func(pts)\n",
    "        check  = np.argwhere(vals<=0.5)  # coordinates that are outsise ionized regions.\n",
    "        num_sz[rr] = check.shape[0]  # record the number of new rays terminated in this loop\n",
    "        xs,ys,zs = np.delete(xs, check),np.delete(ys, check),np.delete(zs, check)  # for the terminated rays,\n",
    "        ls,ms,ns = np.delete(ls, check),np.delete(ms, check),np.delete(ns, check)  # delete the forward step \n",
    "        if verbose:\n",
    "            perc = (rr+1)*100/longest\n",
    "            msg  = '%.1f'%perc + '%'\n",
    "            loading_verbose(msg)\n",
    "        if not xs.size: break\n",
    "    msg  = '100.0' + '%'\n",
    "    loading_verbose(msg)\n",
    "    size_px = np.arange(longest)\n",
    "    return num_sz, size_px\n",
    "\n",
    "def mfp2d(arr, xth=0.5, iterations=1000000, verbose=True):\n",
    "    #2D interpolation is required\n",
    "    #RegularGridInterpolator in scipy(>0.14) is used to do the interpolation\n",
    "\n",
    "    info    = arr.shape\n",
    "    longy\t= max([info[0], info[1]])\n",
    "    longest = int(np.sqrt(2)*longy)\n",
    "    num_sz  = np.zeros(longest)\n",
    "\n",
    "    ar  = np.zeros(arr.shape)\n",
    "    ar[arr >= xth] = 1\n",
    "\n",
    "    loc = np.argwhere(ar == 1)\n",
    "    rand_loc = np.random.randint(0, high=loc.shape[0], size=iterations)\n",
    "    thetas   = np.random.randint(0, 360, size=iterations)\n",
    "    ls       = np.sin(thetas*np.pi/180)\n",
    "    ms       = np.cos(thetas*np.pi/180)\n",
    "\n",
    "    xs,ys    = loc[rand_loc,0],loc[rand_loc,1]\n",
    "\n",
    "    interp_func = RegularGridInterpolator((np.arange(info[0]), np.arange(info[1])), ar, bounds_error=False, fill_value=0)\n",
    "\n",
    "    for rr in range(longest):\n",
    "        xs,ys  = xs+ls,ys+ms\n",
    "        pts    = np.vstack((xs,ys)).T\n",
    "        vals   = interp_func(pts)\n",
    "        check  = np.argwhere(vals<=0.5)\n",
    "        num_sz[rr] = check.shape[0]\n",
    "        xs,ys  = np.delete(xs, check),np.delete(ys, check)\n",
    "        ls,ms  = np.delete(ls, check),np.delete(ms, check)\n",
    "        if verbose:\n",
    "            perc = (rr+1)*100/longest\n",
    "            msg  = '%.1f'%perc + '%'\n",
    "            loading_verbose(msg)\n",
    "        if not xs.size: break\n",
    "    msg  = '100.0' + '%'\n",
    "    loading_verbose(msg)\n",
    "    size_px = np.arange(longest)\n",
    "    return num_sz, size_px\n",
    "\n",
    "\n",
    "def loading_verbose(string):\n",
    "    msg = (\"Completed: \" + string )\n",
    "    sys.stdout.write('\\r'+msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosmological Parameters (Default is used when no input is specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.620136Z",
     "start_time": "2020-07-13T16:47:07.617575Z"
    }
   },
   "outputs": [],
   "source": [
    "cosmo_params = p21c.CosmoParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Parameters, like box length, number of voxels (i.e. resolution) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:47:07.625008Z",
     "start_time": "2020-07-13T16:47:07.622093Z"
    }
   },
   "outputs": [],
   "source": [
    "BOX_LEN=301  # 300, 301\n",
    "HII_DIM=301  # 450, 301\n",
    "\n",
    "user_params = p21c.UserParams(\n",
    "    BOX_LEN=BOX_LEN,  # Box length in Mpc\n",
    "    DIM=4*HII_DIM,      # Number of Voxels for hight resolution \n",
    "    HII_DIM=HII_DIM,  # Number of Voxels for low resolution \n",
    "    N_THREADS=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating initial conditions box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T16:49:19.338938Z",
     "start_time": "2020-07-13T16:47:07.627140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution qued at 2020-07-28 19:46:57.444411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 19:48:59,560 | INFO | Existing init_boxes found and read in (seed=230806296593).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed at 2020-07-28 19:48:59.561585\n",
      "Execution time = 0:02:02.117174\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(f'Excution qued at {start_time}')\n",
    "\n",
    "init_cond = p21c.initial_conditions(\n",
    "    cosmo_params=cosmo_params,\n",
    "    user_params=user_params,\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Execution completed at {end_time}')\n",
    "print(f'Execution time = {execution_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ionized boxes as a function of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 19:49:01,437 | INFO | Existing z=8.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:03,313 | INFO | Existing z=8.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:05,214 | INFO | Existing z=7.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:07,039 | INFO | Existing z=7.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:08,741 | INFO | Existing z=6.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:10,372 | INFO | Existing z=6.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:12,095 | INFO | Existing z=5.5 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:13,878 | INFO | Existing z=5.0 ionized boxes found and read in (seed=230806296593).\n",
      "2020-07-28 19:49:16,228 | INFO | Existing z=4.5 ionized boxes found and read in (seed=230806296593).\n"
     ]
    }
   ],
   "source": [
    "redshifts = np.arange(8.5, 4, -0.5)\n",
    "\n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "# redshifts = np.array([6.5])\n",
    "# ====================================================================================================================\n",
    "\n",
    "ionized_boxes = np.zeros((len(redshifts), HII_DIM, HII_DIM, HII_DIM))\n",
    "\n",
    "for i, z in enumerate(redshifts):\n",
    "    ionized_box = p21c.ionize_box(redshift=z, init_boxes=init_cond).xH_box\n",
    "    ionized_boxes[i] = ionized_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Average Neutral Fraction Distributions as a function of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T17:38:36.997883Z",
     "start_time": "2020-07-13T17:38:36.987749Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_distributions(\n",
    "    boxes=ionized_boxes,\n",
    "    radii=np.arange(8, 17, 1),\n",
    "    iterations=10**2,\n",
    "    sigma_factor=1.4370397097748921*3,\n",
    "    shell_number=6,\n",
    "    progress_status=True\n",
    "):\n",
    "\n",
    "    gaussians = np.zeros((len(redshifts), len(radii), iterations))\n",
    "    \n",
    "    \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#     cubes = np.zeros((len(radii), iterations))\n",
    "# ====================================================================================================================\n",
    "\n",
    "    \n",
    "    if progress_status:\n",
    "        # print progress and local time\n",
    "        start_time = datetime.now()\n",
    "        current_time = start_time\n",
    "        print(f'Progress = 0%, localtime = {start_time}')\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#         cube = Average_Neutral_Fraction_Distribution(\n",
    "#                 box=boxes[0],\n",
    "#                 radius=radius,\n",
    "#                 iteration=iterations,\n",
    "#                 blur_shape='top_hat_cube'\n",
    "#         )\n",
    "        \n",
    "#         cubes[i, :] = cube\n",
    "# ====================================================================================================================\n",
    "        \n",
    "        for ii, radius in enumerate(radii):\n",
    "                        \n",
    "            gaussian = Average_Neutral_Fraction_Distribution(\n",
    "                box=box,\n",
    "                radius=radius,\n",
    "                iteration=iterations,\n",
    "                sigma_factor=sigma_factor,\n",
    "                shell_num=shell_number,\n",
    "                blur_shape='Gaussian_sphere'\n",
    "            )\n",
    "\n",
    "            gaussians[i, ii, :] = gaussian\n",
    "\n",
    "\n",
    "        if progress_status:\n",
    "            # print progress and local time\n",
    "            previous_time = current_time\n",
    "            current_time = datetime.now()\n",
    "            loop_time = current_time - previous_time\n",
    "            elapsed_time = current_time - start_time\n",
    "            print(f'progress = {int(round((i+1)*100/len(boxes)))}%, \\\n",
    "localtime = {current_time}, loopexecuted in {loop_time}, elapsedtime = {elapsed_time}')\n",
    "        \n",
    "    # temporary\n",
    "# ====================================================================================================================\n",
    "#     return gaussians, cubes\n",
    "# ====================================================================================================================\n",
    "    \n",
    "    return gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the distributions and storing the data in global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress = 0%, localtime = 2020-07-28 20:01:23.042685\n",
      "progress = 11%, localtime = 2020-07-28 20:27:40.079837, loopexecuted in 0:26:17.037152, elapsedtime = 0:26:17.037152\n",
      "progress = 22%, localtime = 2020-07-28 20:54:41.005673, loopexecuted in 0:27:00.925836, elapsedtime = 0:53:17.962988\n",
      "progress = 44%, localtime = 2020-07-28 21:47:55.911536, loopexecuted in 0:26:19.963901, elapsedtime = 1:46:32.868851\n",
      "progress = 56%, localtime = 2020-07-28 22:14:13.423296, loopexecuted in 0:26:17.511760, elapsedtime = 2:12:50.380611\n",
      "progress = 67%, localtime = 2020-07-28 22:40:30.292962, loopexecuted in 0:26:16.869666, elapsedtime = 2:39:07.250277\n",
      "progress = 78%, localtime = 2020-07-28 23:06:47.940893, loopexecuted in 0:26:17.647931, elapsedtime = 3:05:24.898208\n",
      "progress = 89%, localtime = 2020-07-28 23:33:04.295102, loopexecuted in 0:26:16.354209, elapsedtime = 3:31:41.252417\n"
     ]
    }
   ],
   "source": [
    "radii = np.arange(9, 1, -1)  # array([34, 32, 30,... 6, 4]) units: voxels (51, 3, -3)\n",
    "iterations = int(7.5e4)\n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "# gaussians, cubes = generate_distributions(\n",
    "# =================================================================================================================== \n",
    "\n",
    "gaussians = generate_distributions(\n",
    "    boxes=ionized_boxes,\n",
    "    radii=radii,\n",
    "    iterations=iterations,\n",
    "    sigma_factor=1.4370397097748921*3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T18:44:11.263417Z",
     "start_time": "2020-07-13T18:44:04.542540Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = int(1e3)\n",
    "histogram(\n",
    "    y1s=gaussians, \n",
    "    \n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "#     y2s=cubes,\n",
    "# =================================================================================================================== \n",
    "    \n",
    "    marker_lines=['-']*len(radii),\n",
    "    y1s_labels=[f'Radius={r*BOX_LEN/HII_DIM:.0f}Mpc' for r in radii],\n",
    "    bin_num=bins,\n",
    "    \n",
    "    # temporary\n",
    "# =================================================================================================================== \n",
    "#     y2s_label='Cube',\n",
    "# =================================================================================================================== \n",
    "    \n",
    "    title=[f'Redshift={z}' for z in redshifts],\n",
    "    shared_title=f'Distribution of Average Neutral Fraction \\\n",
    "(format switch r&z, {bins} bin, {iterations:.2e} iterations)',\n",
    "    shared_y_label='Counts',\n",
    "    shared_x_label='Neutral Fraction',\n",
    "    figure_shape=(3,3), \n",
    "    figure_size=(18,18),\n",
    "    vertical_gap=0.1,\n",
    "    horizontal_gap=0.2,\n",
    "    y_scale='log',\n",
    "#     y_notation='sci',\n",
    "    share_y_axis=False\n",
    "#     dpi=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "21cmfast",
   "language": "python",
   "name": "21cmfast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
